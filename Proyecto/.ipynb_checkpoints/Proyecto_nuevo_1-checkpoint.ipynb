{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dec703c-6ff3-4b13-a6be-fe184c293513",
   "metadata": {},
   "source": [
    "En este scrip se pone el proyecto de manera ordenada con los pasos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb12345-37e4-4a00-8f82-7dc06ab1a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imporamos las librerias \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2 \n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e0d43f-e752-404f-a589-7b9677492cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la ruta a la carpeta que contiene las imágenes que se usaran para entrenar \n",
    "data_test = os.getcwd() + \"/brain_tumor_mris/Testing\"\n",
    "\n",
    "# Cargamos las imágenes que se usaran para entrenar \n",
    "images_test = []\n",
    "labels_test = []\n",
    "for category in os.listdir(data_test):\n",
    "  category_dir = os.path.join(data_test, category)\n",
    "  for image_file in os.listdir(category_dir):\n",
    "    #image_test = cv2.imread(os.path.join(category_dir, image_file), cv2.IMREAD_GRAYSCALE)\n",
    "    image_test = cv2.imread(os.path.join(category_dir, image_file))\n",
    "    image_test = cv2.resize(image_test, (256, 256))  # Redimensionamos las imágenes a 224x224\n",
    "    #cv2.imshow(\"check\", image_train)\n",
    "    #cv2.waitKey(0)\n",
    "    images_test.append(image_test)\n",
    "    labels_test.append(category)\n",
    "#cv2.destroyAllWindows()\n",
    "# Convertimos las imágenes a un formato compatible con TensorFlow\n",
    "images_test = np.array(images_test)\n",
    "images_test = images_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d5888e-8893-45ba-9a7e-5d1d350f301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#De manera opcional podemos imprimir los labels para corroborar que se guardaron de manera correcta \n",
    "#print(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad11ac54-77e2-4c64-a7f6-6c2e46c750d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la ruta a la carpeta que contiene las imágenes que se usaran para probar\n",
    "data_train = os.getcwd() + \"/brain_tumor_mris/Training\"\n",
    "\n",
    "# Cargamos las imágenes que se usaran para entrenar \n",
    "images_train = []\n",
    "labels_train = []\n",
    "for category in os.listdir(data_train):\n",
    "  category_dir = os.path.join(data_train, category)\n",
    "  for image_file in os.listdir(category_dir):\n",
    "    #image_train = cv2.imread(os.path.join(category_dir, image_file), cv2.IMREAD_GRAYSCALE)\n",
    "    image_train = cv2.imread(os.path.join(category_dir, image_file))\n",
    "    image_train = cv2.resize(image_train, (256, 256))  # Redimensionamos las imágenes a 224x224\n",
    "    #cv2.imshow(\"check\", image_train)\n",
    "    #cv2.waitKey(0)\n",
    "    images_train.append(image_train)\n",
    "    labels_train.append(category)\n",
    "#cv2.destroyAllWindows()\n",
    "# Convertimos las imágenes a un formato compatible con TensorFlow\n",
    "images_train = np.array(images_train)\n",
    "images_train = images_train.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5923fd25-5e2c-46cd-bf9e-1cc9cff8df21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizamos las imagenes \n",
    "images_train, images_test = images_train/255.0, images_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24acd7a-69a4-458b-ad5a-b4c85fcb90d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una variable para que sea aleatoria entre los valores de las imagenes para poder representar 25 de ellas al azar\n",
    "indexs = randint(0, len(images_train), 25)\n",
    "indexs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2625f5a1-b487-4136-83be-b49a2425fa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['glioma','meningioma','notumor','pituitary']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i, j in zip(range(25), indexs):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(images_train[j])\n",
    "    # The CIFAR labels happen to be arrays, \n",
    "    # which is why you need the extra index\n",
    "    plt.xlabel(labels_train[j])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc582ab1-606a-4b3c-a056-c62ec58e2547",
   "metadata": {},
   "source": [
    "Una vez que se corrobora que las imagenes se encuentran de manera correcta procedemos a cambiar los valores de las etiquetas por carácteres númericos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19a3a66-10c1-43ba-b4b6-5168dd8fb517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el objeto LabelEncoder\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e297f4b3-ca23-474d-95dd-d867190b99b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar y transformar las etiquetas a números\n",
    "labels_tra = encoder.fit_transform(labels_train)\n",
    "\n",
    "# Mostrar las etiquetas numéricas correspondientes\n",
    "print(labels_tra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f4211b-7f85-4c50-927a-4d27cfa85bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar y transformar las etiquetas a números\n",
    "labels_tes = encoder.fit_transform(labels_test)\n",
    "\n",
    "# Mostrar las etiquetas numéricas correspondientes\n",
    "print(labels_tes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe51781f-2f92-40c0-8826-19440899174c",
   "metadata": {},
   "source": [
    "Un paso antes de comenzar con el diseño del modelo es verificar que las dimensiones sean las correctas en la matrzi generada así como la de las etiquetas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86751d09-f8b5-416b-a82b-bab413e4460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images_train.shape)\n",
    "print(labels_tra.shape)\n",
    "print(images_test.shape)\n",
    "print(labels_tes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81791c8-ab90-4661-b184-02b72d599f16",
   "metadata": {},
   "source": [
    "#### Procedemos a diseñar la CNN\n",
    "\n",
    "#### Definimos nuestra base convulocional CNN\n",
    "La línea de código activation='relu' indica que la salida de la capa de convolución se convertirá en la entrada de la siguiente capa mediante la función ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f487bf61-c27f-4fcd-9525-143e9e79c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "#model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.Conv2D(256, (1, 1), activation='relu', input_shape=(256, 256, 1))) #Ajustamos el modelo para que su entrada sea de 256x256 y en escala de grises\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509c0769-87a6-4b09-8fd9-6ad04ed72a86",
   "metadata": {},
   "source": [
    "##### Agregue capas densas en la parte superior\n",
    "Para completar el modelo, alimentará el último tensor de salida de la base convolucional (de forma (4, 4, 64)) en una o más capas densas para realizar la clasificación. Las capas densas toman vectores como entrada (que son 1D), mientras que la salida actual es un tensor 3D. Primero, aplanará (o desenrollará) la salida 3D a 1D, luego agregará una o más capas densas en la parte superior. CIFAR tiene 10 clases de salida, por lo que usa una capa Densa final con 10 salidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc544ac-e02d-4769-8d25-91520573f0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de30a37a-155a-4538-a44c-afe10758a215",
   "metadata": {},
   "source": [
    "#### Compilamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e1959a-049f-474e-83f5-aaec70f04c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933bb70d-bdc5-43c5-aa82-d30ac8bb3229",
   "metadata": {},
   "source": [
    "#### Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa19b277-9645-484b-af3d-42d8f211b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(images_train, labels_tra, epochs=10, \n",
    "                    validation_data=(images_test, labels_tes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd25f9c-6c57-4e3e-bb1d-d28d5c16fbd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ac38ed-ba61-4393-a5eb-42906dc9a53d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75beb11a-e2f6-41f2-8396-584ad9791cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618cb0b4-c77c-465d-b435-15367abfb1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2692748-a8bc-45d7-aae5-31a268ecbbcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ef10e0-ebb6-4546-bd79-2494c5ce5585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd19550-339e-413b-96a2-158ab29b64c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badd8bab-2a95-47b0-add1-1afb5e48fe1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262178e7-eb7e-4a09-88a8-10dbf5b788fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470f8367-5280-4e9e-aa2c-0a9c89805764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e904d0f-b7d9-4c9e-b51a-a24f59554d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0527db62-98df-4c72-a555-d434fa9c5712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25d762e-74ad-45f0-ab50-d8e981675516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85556b7b-cb35-48e3-a772-1efc07d635ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530d2577-d217-4c70-9365-ac86d0a7cd0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2ddb20-4c58-44bf-bef5-294cc81f1ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09b3d81-35ec-499f-87e9-c7b8fce7f5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8292a8e-d585-4a0e-8c9f-baeb99efa15d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
